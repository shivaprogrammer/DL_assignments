# -*- coding: utf-8 -*-
"""M24CSA027_M24CSA029.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q9djjSPkDX7irLgzfYqKi66ZZ5kAGGco
"""

import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
from torchvision.models import resnet34
import torch.nn as nn
import torch.nn.functional as F
from tqdm import tqdm
import os
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns

"""<h3>Loading the Test Data </h3>"""

transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),
])

full_test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)

test_size = len(full_test_dataset)
test_10_size = int(0.1 * test_size)
test_20_size = int(0.2 * test_size)

indices = list(range(test_size))
test_10_indices = indices[:test_10_size]
test_20_indices = indices[test_10_size: test_10_size + test_20_size]

test_10_subset = Subset(full_test_dataset, test_10_indices)
test_20_subset = Subset(full_test_dataset, test_20_indices)

test_10_dataloader = DataLoader(dataset = test_10_subset, batch_size = 8)
test_20_dataloader = DataLoader(dataset = test_20_subset, batch_size = 8)

"""<h3>Teacher Model </h3>"""

teacher_model = resnet34(weights = None)
num_features = teacher_model.fc.in_features
print('Initial Final Output dim:', teacher_model.fc.out_features)
teacher_model.fc = torch.nn.Linear(num_features, 100)
print('Changed Final Output dim:', teacher_model.fc.out_features)

print(torch.cuda.is_available())
print("CUDA version according to PyTorch:", torch.version.cuda)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
weights_path = 'saved_weights/best_resnet34_cifar100.pth'
resnet_state_dict = torch.load(weights_path, map_location=device)
teacher_model.load_state_dict(state_dict=resnet_state_dict)
teacher_model.to(device)

# Setting teacher model to eval mode, as we are not training it
teacher_model.eval()

def evaluate_model(model, dataloader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    return accuracy

acc_10 = evaluate_model(teacher_model, test_10_dataloader, device)
print(f"Teacher Model Accuracy on 10% Test Subset: {acc_10:.2f}%")

acc_20 = evaluate_model(teacher_model, test_20_dataloader, device)
print(f"Teacher Model Accuracy on 20% Test Subset: {acc_20:.2f}%")

"""<h3>Analsysing Parameter Counts</h3>"""

# numel multiply all dimensions of tensor to get total elements
def count_model_params(model, name):
    params_count = sum(p.numel() for p in model.parameters())
    print(f"{name} model parameters: {params_count}")
    return params_count

teach_params_count = count_model_params(teacher_model, 'Teacher')

student1_params_count = int(0.1 * teach_params_count)
student2_params_count = int(0.2 * teach_params_count)
print(f"Student1 model parameters needed: {student1_params_count}")
print(f"Student2 model parameters needed: {student2_params_count}")

"""<h3>Student Model</h3>"""

class BaseStudentBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, expand_ratio=1):
        super(BaseStudentBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, in_channels * expand_ratio, kernel_size=1, stride=1, padding=0, bias=False)
        self.bn1 = nn.BatchNorm2d(in_channels * expand_ratio)
        self.conv2 = nn.Conv2d(in_channels * expand_ratio, out_channels, kernel_size, stride, padding, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.expand_ratio = expand_ratio

    def forward(self, x):
        identity = x

        out = F.relu6(self.bn1(self.conv1(x)))
        out = F.relu6(self.bn2(self.conv2(out)))

        if identity.shape[1] == out.shape[1]:
            out += identity
        return out

class Student1(nn.Module):
    def __init__(self, num_classes=100):
        super(Student1, self).__init__()
        self.stem_conv = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)
        self.stem_bn = nn.BatchNorm2d(32)
        self.blocks = nn.Sequential(
            BaseStudentBlock(32, 16, expand_ratio=1),
            BaseStudentBlock(16, 24, expand_ratio=3),
            BaseStudentBlock(24, 40, expand_ratio=3),
            BaseStudentBlock(40, 80, expand_ratio=3),
            BaseStudentBlock(80, 112, expand_ratio=3),
            BaseStudentBlock(112, 192, expand_ratio=3),
            BaseStudentBlock(192, 300, expand_ratio=2)
        )
        self.global_pool = nn.AdaptiveAvgPool2d(1) # global pool give 1 value per channel
        self.fc = nn.Linear(300, num_classes)

    def forward(self, x):
        x = F.relu6(self.stem_bn(self.stem_conv(x)))
        x = self.blocks(x)
        x = self.global_pool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x

class Student2(nn.Module):
    def __init__(self, num_classes = 100):
        super(Student2, self).__init__()
        self.stem_conv = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)
        self.stem_bn = nn.BatchNorm2d(32)
        self.blocks = nn.Sequential(
            BaseStudentBlock(32, 16, expand_ratio=1),
            BaseStudentBlock(16, 24, expand_ratio=5),
            BaseStudentBlock(24, 40, expand_ratio=5),
            BaseStudentBlock(40, 80, expand_ratio=5),
            BaseStudentBlock(80, 100, expand_ratio=5),
            BaseStudentBlock(100, 188, expand_ratio=5),
            BaseStudentBlock(188, 300, expand_ratio=5)
        )
        self.global_pool = nn.AdaptiveAvgPool2d(1) # global pool give 1 value per channel
        self.fc = nn.Linear(300, num_classes)

    def forward(self, x):
        x = F.relu6(self.stem_bn(self.stem_conv(x)))
        x = self.blocks(x)
        x = self.global_pool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        return x

student1_model = Student1(100)
student2_model = Student2(100)
count_model_params(student1_model, 'Student1')
count_model_params(student2_model, 'Student2')

class GeneratorA(nn.Module):
    def __init__(self, noise_dim=100, output_channels=3, img_size=32):
        super(GeneratorA, self).__init__()
        self.noise_dim = noise_dim
        self.output_channels = output_channels
        self.img_size = img_size
        self.init_size = img_size // 16  # Start from 14x14 if output is 224x224

        self.fc = nn.Sequential(
            nn.Linear(noise_dim, 512 * self.init_size * self.init_size),
            nn.BatchNorm1d(512 * self.init_size * self.init_size),
            nn.LeakyReLU(0.2, inplace=True)
        )

        self.conv_blocks = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bicubic'),  # 14 -> 28
            nn.Conv2d(512, 256, 3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Upsample(scale_factor=2, mode='bicubic'),  # 28 -> 56
            nn.Conv2d(256, 128, 3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Upsample(scale_factor=2, mode='bicubic'),  # 56 -> 112
            nn.Conv2d(128, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Upsample(scale_factor=2, mode='bicubic'),  # 112 -> 224
            nn.Conv2d(64, output_channels, 3, stride=1, padding=1),
            nn.Tanh()
        )

    def forward(self, z):
        batch_size = z.size(0)
        out = self.fc(z)
        out = out.view(batch_size, 512, self.init_size, self.init_size)
        img = self.conv_blocks(out)
        return img

# Example usage:
if __name__ == '__main__':
    noise_dim = 100
    img_size = 32
    channels = 3
    batch_size = 64

    generator = GeneratorA(noise_dim=noise_dim, output_channels=channels, img_size=img_size)

    z = torch.randn(batch_size, noise_dim)

    fake_images = generator(z)

    print(f"\nInput noise shape: {z.shape}")
    print(f"Output image shape: {fake_images.shape}")

    num_params = sum(p.numel() for p in generator.parameters() if p.requires_grad)
    print(f"Number of trainable parameters in Generator: {num_params:,}")

"""<h3>Training Loop</h3>"""

cifar100_mean = torch.tensor([0.5071, 0.4867, 0.4408], device=device).view(1, 3, 1, 1)
cifar100_std = torch.tensor([0.2675, 0.2565, 0.2761], device=device).view(1, 3, 1, 1)

def transform_generated_for_processing(generated_images):
    # 1. Rescale from [-1, 1] to [0, 1]
    images_0_1 = (generated_images + 1.0) / 2.0
    # 2. Apply CIFAR-100 normalization
    normalized_images = (images_0_1 - cifar100_mean) / cifar100_std
    return normalized_images

LEARNING_RATE = 1e-4
MOMENTUM = 0.9
WEIGHT_DECAY = 5e-5
EPOCHS = 500
K_S = 5 # Inner student updates per generator update
K_G = 1
BATCH_SIZE = 128
NOISE_DIM = 100
IMG_SIZE = 32
BEST_ACCURACY = 0.0
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f'Using device: {DEVICE}')

def get_student_optimizer(student_model, lr = LEARNING_RATE):
    optimizer_S = torch.optim.Adam(student_model.parameters(), lr)
    return optimizer_S

def get_generator_optimizer(generator_model, lr = LEARNING_RATE):
    optimizer_G = torch.optim.Adam(generator_model.parameters(), lr * 0.7)
    return optimizer_G

def get_best_accuracy(path = 'best_accuracy_s2.txt'):
    best_accuracy = 0.0
    with open(path, mode='r') as f:
        best_accuracy = f.readline()
        return float(best_accuracy)

def save_best_accuracy(best_accuracy, path = 'best_accuracy_s2.txt'):
    print('Saving Best Accuracy...')
    with open(path, mode='w') as f:
        f.write(str(best_accuracy))

def plot_accuracy_vs_epoch(accuracy_list, step_size = 5):
    epochs = range(step_size, len(accuracy_list)*step_size + 1, step_size)
    fig, ax = plt.subplots(figsize=(10, 5))

    ax.plot(epochs, accuracy_list, marker='o', linestyle='-', color='b')

    ax.set_xlabel("Epoch")
    ax.set_ylabel("Accuracy")
    ax.set_title("Accuracy vs Epoch")

    ax.grid(True)

    plt.show()

def train(student_model, teacher_model, generator_model, num_epochs=EPOCHS, k_s=K_S, k_g = K_G, device=DEVICE,
          batch_size=BATCH_SIZE, noise_dim=NOISE_DIM,
          eval_dataloader = test_20_dataloader,
          gen_save_path = 'saved_weights/generator_model.pth',
          student_save_path = 'saved_weights/student_model.pth',
          best_accuracy_path = 'best_accuracy_s2.txt'):

    student_model = student_model.to(device)
    teacher_model = teacher_model.to(device)
    generator_model = generator_model.to(device)
    teacher_model.eval()
    accuracy_list = []

    try:
        BEST_ACCURACY = get_best_accuracy(best_accuracy_path)
    except:
        BEST_ACCURACY = 0.0

    optimizerS = get_student_optimizer(student_model)
    optimizerG = get_generator_optimizer(generator_model)

    for epoch in range(num_epochs):

        # Train the student model, keep genrator on eval mode
        student_model.train()
        generator_model.eval()

        student_epoch_loss = 0.0

        # Use leave=False for the inner loop so it doesn't persist after completion
        student_loop = tqdm(range(k_s), desc=f"[Epoch {epoch+1}/{num_epochs}] Student Updates", leave=False)

        for step in student_loop:
            optimizerS.zero_grad()
            z = torch.randn(batch_size, noise_dim, device=device)
            fake_images = generator_model(z)

            processed_input_images = transform_generated_for_processing(fake_images.detach())

            with torch.no_grad():
                teacher_output = teacher_model(processed_input_images)

            student_output = student_model(processed_input_images)

            loss_s = torch.mean(torch.abs(teacher_output.detach() - student_output))
            loss_s.backward()
            torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)
            optimizerS.step()

            student_epoch_loss += loss_s.item()
            student_loop.set_postfix({"Student Loss": f"{loss_s.item():.4f}"})

        avg_student_loss = student_epoch_loss / k_s
        print(f"[Epoch {epoch+1}] Avg Student Loss: {avg_student_loss:.4f}")

        # Train the generator
        student_model.eval()
        generator_model.train()
        generator_epoch_loss = 0.0

        # Generate fake images
        generator_loop = tqdm(range(k_g), desc=f"[Epoch {epoch+1}/{num_epochs}] Generator Updates", leave=False)
        for step in generator_loop:
            optimizerG.zero_grad()
            z = torch.randn(batch_size, noise_dim, device=device)
            fake_images = generator_model(z)
            processed_input_images = transform_generated_for_processing(fake_images.detach())

            with torch.no_grad():
                teacher_output = teacher_model(processed_input_images)

            student_output = student_model(processed_input_images)

            loss_mae = torch.mean(torch.abs(teacher_output.detach() - student_output))
            loss_g = -loss_mae
            loss_g.backward()

            torch.nn.utils.clip_grad_norm_(generator_model.parameters(), max_norm=1.0)
            optimizerG.step()

            generator_epoch_loss += loss_g.item()
            generator_loop.set_postfix({"Generator Loss": f"{loss_g.item():.4f}"})

        avg_generator_loss = generator_epoch_loss / k_g
        print(f"[Epoch {epoch+1}] Avg Generator Loss: {avg_generator_loss:.4f}")


        if((epoch + 1) % 5 == 0):
            student_model.eval()
            print(f"[Epoch {epoch+1}] Evaluating student accuracy...")
            current_accuracy = evaluate_model(student_model, eval_dataloader, device)
            print(f"[Epoch {epoch+1}] Student Accuracy on Test Set: {current_accuracy:.2f}%")

            # --- Save Best Model ---
            accuracy_list.append(current_accuracy)
            if current_accuracy > BEST_ACCURACY:
                BEST_ACCURACY = current_accuracy
                print(f"[Epoch {epoch+1}] New best accuracy! Saving model to {student_save_path}")
                torch.save(student_model.state_dict(), student_save_path)

                torch.save(generator_model.state_dict(), gen_save_path.replace('.pth', '_best.pth'))
    plot_accuracy_vs_epoch(accuracy_list=accuracy_list)
    save_best_accuracy(BEST_ACCURACY, best_accuracy_path)

generator_model = GeneratorA(noise_dim=NOISE_DIM, output_channels=3, img_size = IMG_SIZE)
student2_model = Student2(100)

if(os.path.exists('saved_weights/student2_model.pth')):
      student2_model.load_state_dict(torch.load('saved_weights/student2_model.pth'))

if(os.path.exists('saved_weights/generator_model_best.pth')):
      generator_model.load_state_dict(torch.load('saved_weights/generator_model_best.pth'))

train(student_model=student2_model,
      teacher_model=teacher_model,
      generator_model=generator_model,
      batch_size=BATCH_SIZE,
      student_save_path='saved_weights/student2_model.pth',
      best_accuracy_path='best_accuracy_s2.txt')

generator_model = GeneratorA(noise_dim=NOISE_DIM, output_channels=3, img_size = IMG_SIZE)
student1_model = Student1(100)

if(os.path.exists('saved_weights/student1_model.pth')):
      student1_model.load_state_dict(torch.load('saved_weights/student1_model.pth'))

if(os.path.exists('saved_weights/generator_model_best_s1.pth')):
      generator_model.load_state_dict(torch.load('saved_weights/generator_model_best_s1.pth'))

train(student_model=student1_model,
      teacher_model=teacher_model,
      generator_model=generator_model,
      batch_size=BATCH_SIZE,
      student_save_path='saved_weights/student1_model.pth',
      best_accuracy_path='best_accuracy_s1.txt')

def display_generated_images(generator_model, num_images=5, noise_dim=NOISE_DIM, device=DEVICE):
    generator_model.eval()
    with torch.no_grad():
        noise = torch.randn(num_images, noise_dim).to(device)
        generated_images = generator_model(noise).cpu()

    generated_images = (generated_images + 1) / 2

    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))
    for i in range(num_images):
      axes[i].imshow(generated_images[i].permute(1, 2, 0))
      axes[i].axis('off')
    plt.show()


def plot_confusion_matrix(model, dataloader, device):
  model.eval()
  y_true = []
  y_pred = []
  with torch.no_grad():
      for images, labels in dataloader:
          images, labels = images.to(device), labels.to(device)
          outputs = model(images)
          _, predicted = torch.max(outputs.data, 1)
          y_true.extend(labels.cpu().numpy())
          y_pred.extend(predicted.cpu().numpy())

  y_true = y_true[0: 10]
  y_pred = y_pred[0: 10]

  cm = confusion_matrix(y_true, y_pred)
  plt.figure(figsize=(10, 10))
  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
  plt.xlabel('Predicted')
  plt.ylabel('True')
  plt.title('Confusion Matrix')
  plt.show()


# Evaluate student models
def evaluate_models(model, dataloader, device, name):
  accuracy = evaluate_model(model, dataloader, device)
  print(f"{name} Accuracy: {accuracy:.2f}%")
  plot_confusion_matrix(model, dataloader, device)
  count_model_params(model, name)
  display_generated_images(generator_model, device=device)


student1_model = Student1(100).to(device)
student2_model = Student2(100).to(device)


student1_model.load_state_dict(torch.load('saved_weights/student1_model.pth', map_location=device))
student2_model.load_state_dict(torch.load('saved_weights/student2_model.pth', map_location=device))


# Evaluate Student 1
print("\nStudent 1 Evaluation (10% data):")
evaluate_models(student1_model, test_10_dataloader, device, "Student 1 (10% data)")

print("\nStudent 1 Evaluation (20% data):")
evaluate_models(student1_model, test_20_dataloader, device, "Student 1 (20% data)")


# Evaluate Student 2
print("\nStudent 2 Evaluation (10% data):")
evaluate_models(student2_model, test_10_dataloader, device, "Student 2 (10% data)")

print("\nStudent 2 Evaluation (20% data):")
evaluate_models(student2_model, test_20_dataloader, device, "Student 2 (20% data)")

